{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing pipeline\n",
    "preprocessing = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    # Include normalization if required for your model\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with 10 Epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models.vision_transformer import vit_b_32\n",
    "\n",
    "# Load the saved state dictionary\n",
    "model_path = r'D:\\Kuliah\\Matkul\\Semester 7\\TA\\Kode\\ViT\\vit_model_10_epoch.pth'\n",
    "state_dict = torch.load(model_path)\n",
    "\n",
    "# Rename keys to match the current model's expected keys\n",
    "new_state_dict = {}\n",
    "for key in state_dict.keys():\n",
    "    if key == \"heads.weight\":\n",
    "        new_state_dict[\"heads.head.weight\"] = state_dict[key]\n",
    "    elif key == \"heads.bias\":\n",
    "        new_state_dict[\"heads.head.bias\"] = state_dict[key]\n",
    "    else:\n",
    "        new_state_dict[key] = state_dict[key]\n",
    "\n",
    "# Initialize the model\n",
    "vit_model = vit_b_32()\n",
    "\n",
    "# Replace the classification head to match your saved model\n",
    "vit_model.heads.head = torch.nn.Linear(vit_model.heads.head.in_features, 8)\n",
    "\n",
    "# Load the updated state dictionary\n",
    "vit_model.load_state_dict(new_state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "vit_model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: DSC06492.JPG\n",
      "Predicted class for DSC06492.JPG: Class 7\n",
      "Processing file: DSC06509.JPG\n",
      "Predicted class for DSC06509.JPG: Class 7\n",
      "Processing file: DSC06530.JPG\n",
      "Predicted class for DSC06530.JPG: Class 7\n",
      "Processing file: DSC06543.JPG\n",
      "Predicted class for DSC06543.JPG: Class 7\n",
      "Processing file: DSC06587.JPG\n",
      "Predicted class for DSC06587.JPG: Class 7\n",
      "Processing file: DSC06884.JPG\n",
      "Predicted class for DSC06884.JPG: Class 6\n",
      "Processing file: DSC06927.JPG\n",
      "Predicted class for DSC06927.JPG: Class 6\n",
      "Processing file: DSC07006.JPG\n",
      "Predicted class for DSC07006.JPG: Class 6\n",
      "Processing file: DSC07031.JPG\n",
      "Predicted class for DSC07031.JPG: Class 6\n",
      "Processing file: DSC07109.JPG\n",
      "Predicted class for DSC07109.JPG: Class 6\n",
      "Processing file: DSC07301.JPG\n",
      "Predicted class for DSC07301.JPG: Class 5\n",
      "Processing file: DSC07490.JPG\n",
      "Predicted class for DSC07490.JPG: Class 5\n",
      "Processing file: DSC07513.JPG\n",
      "Predicted class for DSC07513.JPG: Class 5\n",
      "Processing file: DSC07535.JPG\n",
      "Predicted class for DSC07535.JPG: Class 5\n",
      "Processing file: DSC07623.JPG\n",
      "Predicted class for DSC07623.JPG: Class 5\n",
      "Processing file: DSC07715.JPG\n",
      "Predicted class for DSC07715.JPG: Class 4\n",
      "Processing file: DSC07753.JPG\n",
      "Predicted class for DSC07753.JPG: Class 4\n",
      "Processing file: DSC07897.JPG\n",
      "Predicted class for DSC07897.JPG: Class 4\n",
      "Processing file: DSC07971.JPG\n",
      "Predicted class for DSC07971.JPG: Class 4\n",
      "Processing file: DSC07975.JPG\n",
      "Predicted class for DSC07975.JPG: Class 4\n",
      "Processing file: DSC08228.JPG\n",
      "Predicted class for DSC08228.JPG: Class 3\n",
      "Processing file: DSC08241.JPG\n",
      "Predicted class for DSC08241.JPG: Class 3\n",
      "Processing file: DSC08262.JPG\n",
      "Predicted class for DSC08262.JPG: Class 3\n",
      "Processing file: DSC08283.JPG\n",
      "Predicted class for DSC08283.JPG: Class 3\n",
      "Processing file: DSC08550.JPG\n",
      "Predicted class for DSC08550.JPG: Class 3\n",
      "Processing file: DSC08602.JPG\n",
      "Predicted class for DSC08602.JPG: Class 3\n",
      "Processing file: DSC08656.JPG\n",
      "Predicted class for DSC08656.JPG: Class 3\n",
      "Processing file: DSC08788.JPG\n",
      "Predicted class for DSC08788.JPG: Class 3\n",
      "Processing file: DSC08833.JPG\n",
      "Predicted class for DSC08833.JPG: Class 3\n",
      "Processing file: DSC08891.JPG\n",
      "Predicted class for DSC08891.JPG: Class 3\n",
      "Processing file: DSC09035.JPG\n",
      "Predicted class for DSC09035.JPG: Class 1\n",
      "Processing file: DSC09082.JPG\n",
      "Predicted class for DSC09082.JPG: Class 1\n",
      "Processing file: DSC09116.JPG\n",
      "Predicted class for DSC09116.JPG: Class 1\n",
      "Processing file: DSC09150.JPG\n",
      "Predicted class for DSC09150.JPG: Class 1\n",
      "Processing file: DSC09175.JPG\n",
      "Predicted class for DSC09175.JPG: Class 1\n",
      "Processing file: DSC09541.JPG\n",
      "Predicted class for DSC09541.JPG: Class 0\n",
      "Processing file: DSC09564.JPG\n",
      "Predicted class for DSC09564.JPG: Class 0\n",
      "Processing file: DSC09624.JPG\n",
      "Predicted class for DSC09624.JPG: Class 0\n",
      "Processing file: DSC09660.JPG\n",
      "Predicted class for DSC09660.JPG: Class 0\n",
      "Processing file: DSC09678.JPG\n",
      "Predicted class for DSC09678.JPG: Class 0\n"
     ]
    }
   ],
   "source": [
    "# Move the model to the same device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vit_model.to(device)\n",
    "\n",
    "# Function to load an image and make a prediction\n",
    "def predict_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    input_tensor = preprocessing(image).unsqueeze(0)  # Add batch dimension\n",
    "    input_tensor = input_tensor.to(device)  # Move to device if using GPU\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = vit_model(input_tensor)\n",
    "        _, predicted_class = torch.max(output, 1)\n",
    "\n",
    "    return predicted_class.item()\n",
    "\n",
    "# Define the directory where the test images are stored\n",
    "test_dir = r'D:\\Kuliah\\Matkul\\Semester 7\\TA\\Dataset\\Test Set'\n",
    "\n",
    "# Function to run inference on all images in the test directory\n",
    "def run_inference_on_directory(test_dir):\n",
    "    # Iterate through each file in the test directory\n",
    "    for file_name in os.listdir(test_dir):\n",
    "        file_path = os.path.join(test_dir, file_name)\n",
    "        \n",
    "        # Check if the file is an image (optional check for file extension)\n",
    "        if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            print(f\"Processing file: {file_name}\")\n",
    "            \n",
    "            # Run the prediction on the image\n",
    "            predicted_class = predict_image(file_path)\n",
    "            print(f\"Predicted class for {file_name}: Class {predicted_class}\")\n",
    "\n",
    "# Run inference on the entire test dataset\n",
    "run_inference_on_directory(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with 20 Epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models.vision_transformer import vit_b_32\n",
    "\n",
    "# Load the saved state dictionary\n",
    "model_path = r'D:\\Kuliah\\Matkul\\Semester 7\\TA\\Kode\\ViT\\vit_model_20_epoch.pth'\n",
    "state_dict = torch.load(model_path)\n",
    "\n",
    "# Rename keys to match the current model's expected keys\n",
    "new_state_dict = {}\n",
    "for key in state_dict.keys():\n",
    "    if key == \"heads.weight\":\n",
    "        new_state_dict[\"heads.head.weight\"] = state_dict[key]\n",
    "    elif key == \"heads.bias\":\n",
    "        new_state_dict[\"heads.head.bias\"] = state_dict[key]\n",
    "    else:\n",
    "        new_state_dict[key] = state_dict[key]\n",
    "\n",
    "# Initialize the model\n",
    "vit_model = vit_b_32()\n",
    "\n",
    "# Replace the classification head to match your saved model\n",
    "vit_model.heads.head = torch.nn.Linear(vit_model.heads.head.in_features, 8)\n",
    "\n",
    "# Load the updated state dictionary\n",
    "vit_model.load_state_dict(new_state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "vit_model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: DSC06492.JPG\n",
      "Predicted class for DSC06492.JPG: Class 7\n",
      "Processing file: DSC06509.JPG\n",
      "Predicted class for DSC06509.JPG: Class 7\n",
      "Processing file: DSC06530.JPG\n",
      "Predicted class for DSC06530.JPG: Class 7\n",
      "Processing file: DSC06543.JPG\n",
      "Predicted class for DSC06543.JPG: Class 7\n",
      "Processing file: DSC06587.JPG\n",
      "Predicted class for DSC06587.JPG: Class 7\n",
      "Processing file: DSC06884.JPG\n",
      "Predicted class for DSC06884.JPG: Class 6\n",
      "Processing file: DSC06927.JPG\n",
      "Predicted class for DSC06927.JPG: Class 6\n",
      "Processing file: DSC07006.JPG\n",
      "Predicted class for DSC07006.JPG: Class 6\n",
      "Processing file: DSC07031.JPG\n",
      "Predicted class for DSC07031.JPG: Class 6\n",
      "Processing file: DSC07109.JPG\n",
      "Predicted class for DSC07109.JPG: Class 6\n",
      "Processing file: DSC07301.JPG\n",
      "Predicted class for DSC07301.JPG: Class 5\n",
      "Processing file: DSC07490.JPG\n",
      "Predicted class for DSC07490.JPG: Class 5\n",
      "Processing file: DSC07513.JPG\n",
      "Predicted class for DSC07513.JPG: Class 5\n",
      "Processing file: DSC07535.JPG\n",
      "Predicted class for DSC07535.JPG: Class 5\n",
      "Processing file: DSC07623.JPG\n",
      "Predicted class for DSC07623.JPG: Class 5\n",
      "Processing file: DSC07715.JPG\n",
      "Predicted class for DSC07715.JPG: Class 4\n",
      "Processing file: DSC07753.JPG\n",
      "Predicted class for DSC07753.JPG: Class 4\n",
      "Processing file: DSC07897.JPG\n",
      "Predicted class for DSC07897.JPG: Class 4\n",
      "Processing file: DSC07971.JPG\n",
      "Predicted class for DSC07971.JPG: Class 4\n",
      "Processing file: DSC07975.JPG\n",
      "Predicted class for DSC07975.JPG: Class 4\n",
      "Processing file: DSC08228.JPG\n",
      "Predicted class for DSC08228.JPG: Class 3\n",
      "Processing file: DSC08241.JPG\n",
      "Predicted class for DSC08241.JPG: Class 3\n",
      "Processing file: DSC08262.JPG\n",
      "Predicted class for DSC08262.JPG: Class 3\n",
      "Processing file: DSC08283.JPG\n",
      "Predicted class for DSC08283.JPG: Class 3\n",
      "Processing file: DSC08550.JPG\n",
      "Predicted class for DSC08550.JPG: Class 3\n",
      "Processing file: DSC08602.JPG\n",
      "Predicted class for DSC08602.JPG: Class 2\n",
      "Processing file: DSC08656.JPG\n",
      "Predicted class for DSC08656.JPG: Class 2\n",
      "Processing file: DSC08788.JPG\n",
      "Predicted class for DSC08788.JPG: Class 2\n",
      "Processing file: DSC08833.JPG\n",
      "Predicted class for DSC08833.JPG: Class 2\n",
      "Processing file: DSC08891.JPG\n",
      "Predicted class for DSC08891.JPG: Class 3\n",
      "Processing file: DSC09035.JPG\n",
      "Predicted class for DSC09035.JPG: Class 1\n",
      "Processing file: DSC09082.JPG\n",
      "Predicted class for DSC09082.JPG: Class 1\n",
      "Processing file: DSC09116.JPG\n",
      "Predicted class for DSC09116.JPG: Class 1\n",
      "Processing file: DSC09150.JPG\n",
      "Predicted class for DSC09150.JPG: Class 1\n",
      "Processing file: DSC09175.JPG\n",
      "Predicted class for DSC09175.JPG: Class 1\n",
      "Processing file: DSC09541.JPG\n",
      "Predicted class for DSC09541.JPG: Class 0\n",
      "Processing file: DSC09564.JPG\n",
      "Predicted class for DSC09564.JPG: Class 0\n",
      "Processing file: DSC09624.JPG\n",
      "Predicted class for DSC09624.JPG: Class 0\n",
      "Processing file: DSC09660.JPG\n",
      "Predicted class for DSC09660.JPG: Class 0\n",
      "Processing file: DSC09678.JPG\n",
      "Predicted class for DSC09678.JPG: Class 0\n"
     ]
    }
   ],
   "source": [
    "# Move the model to the same device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vit_model.to(device)\n",
    "\n",
    "# Function to load an image and make a prediction\n",
    "def predict_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    input_tensor = preprocessing(image).unsqueeze(0)  # Add batch dimension\n",
    "    input_tensor = input_tensor.to(device)  # Move to device if using GPU\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = vit_model(input_tensor)\n",
    "        _, predicted_class = torch.max(output, 1)\n",
    "\n",
    "    return predicted_class.item()\n",
    "\n",
    "# Define the directory where the test images are stored\n",
    "test_dir = r'D:\\Kuliah\\Matkul\\Semester 7\\TA\\Dataset\\Test Set'\n",
    "\n",
    "# Function to run inference on all images in the test directory\n",
    "def run_inference_on_directory(test_dir):\n",
    "    # Iterate through each file in the test directory\n",
    "    for file_name in os.listdir(test_dir):\n",
    "        file_path = os.path.join(test_dir, file_name)\n",
    "        \n",
    "        # Check if the file is an image (optional check for file extension)\n",
    "        if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            print(f\"Processing file: {file_name}\")\n",
    "            \n",
    "            # Run the prediction on the image\n",
    "            predicted_class = predict_image(file_path)\n",
    "            print(f\"Predicted class for {file_name}: Class {predicted_class}\")\n",
    "\n",
    "# Run inference on the entire test dataset\n",
    "run_inference_on_directory(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with 50 Epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models.vision_transformer import vit_b_32\n",
    "\n",
    "# Load the saved state dictionary\n",
    "model_path = r'D:\\Kuliah\\Matkul\\Semester 7\\TA\\Kode\\ViT\\vit_model_50_epoch.pth'\n",
    "state_dict = torch.load(model_path)\n",
    "\n",
    "# Rename keys to match the current model's expected keys\n",
    "new_state_dict = {}\n",
    "for key in state_dict.keys():\n",
    "    if key == \"heads.weight\":\n",
    "        new_state_dict[\"heads.head.weight\"] = state_dict[key]\n",
    "    elif key == \"heads.bias\":\n",
    "        new_state_dict[\"heads.head.bias\"] = state_dict[key]\n",
    "    else:\n",
    "        new_state_dict[key] = state_dict[key]\n",
    "\n",
    "# Initialize the model\n",
    "vit_model = vit_b_32()\n",
    "\n",
    "# Replace the classification head to match your saved model\n",
    "vit_model.heads.head = torch.nn.Linear(vit_model.heads.head.in_features, 8)\n",
    "\n",
    "# Load the updated state dictionary\n",
    "vit_model.load_state_dict(new_state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "vit_model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: DSC06492.JPG\n",
      "Predicted class for DSC06492.JPG: Class 7\n",
      "Processing file: DSC06509.JPG\n",
      "Predicted class for DSC06509.JPG: Class 7\n",
      "Processing file: DSC06530.JPG\n",
      "Predicted class for DSC06530.JPG: Class 7\n",
      "Processing file: DSC06543.JPG\n",
      "Predicted class for DSC06543.JPG: Class 7\n",
      "Processing file: DSC06587.JPG\n",
      "Predicted class for DSC06587.JPG: Class 7\n",
      "Processing file: DSC06884.JPG\n",
      "Predicted class for DSC06884.JPG: Class 6\n",
      "Processing file: DSC06927.JPG\n",
      "Predicted class for DSC06927.JPG: Class 6\n",
      "Processing file: DSC07006.JPG\n",
      "Predicted class for DSC07006.JPG: Class 6\n",
      "Processing file: DSC07031.JPG\n",
      "Predicted class for DSC07031.JPG: Class 6\n",
      "Processing file: DSC07109.JPG\n",
      "Predicted class for DSC07109.JPG: Class 6\n",
      "Processing file: DSC07301.JPG\n",
      "Predicted class for DSC07301.JPG: Class 5\n",
      "Processing file: DSC07490.JPG\n",
      "Predicted class for DSC07490.JPG: Class 5\n",
      "Processing file: DSC07513.JPG\n",
      "Predicted class for DSC07513.JPG: Class 5\n",
      "Processing file: DSC07535.JPG\n",
      "Predicted class for DSC07535.JPG: Class 5\n",
      "Processing file: DSC07623.JPG\n",
      "Predicted class for DSC07623.JPG: Class 5\n",
      "Processing file: DSC07715.JPG\n",
      "Predicted class for DSC07715.JPG: Class 4\n",
      "Processing file: DSC07753.JPG\n",
      "Predicted class for DSC07753.JPG: Class 4\n",
      "Processing file: DSC07897.JPG\n",
      "Predicted class for DSC07897.JPG: Class 4\n",
      "Processing file: DSC07971.JPG\n",
      "Predicted class for DSC07971.JPG: Class 4\n",
      "Processing file: DSC07975.JPG\n",
      "Predicted class for DSC07975.JPG: Class 4\n",
      "Processing file: DSC08228.JPG\n",
      "Predicted class for DSC08228.JPG: Class 3\n",
      "Processing file: DSC08241.JPG\n",
      "Predicted class for DSC08241.JPG: Class 3\n",
      "Processing file: DSC08262.JPG\n",
      "Predicted class for DSC08262.JPG: Class 3\n",
      "Processing file: DSC08283.JPG\n",
      "Predicted class for DSC08283.JPG: Class 3\n",
      "Processing file: DSC08550.JPG\n",
      "Predicted class for DSC08550.JPG: Class 3\n",
      "Processing file: DSC08602.JPG\n",
      "Predicted class for DSC08602.JPG: Class 3\n",
      "Processing file: DSC08656.JPG\n",
      "Predicted class for DSC08656.JPG: Class 3\n",
      "Processing file: DSC08788.JPG\n",
      "Predicted class for DSC08788.JPG: Class 3\n",
      "Processing file: DSC08833.JPG\n",
      "Predicted class for DSC08833.JPG: Class 3\n",
      "Processing file: DSC08891.JPG\n",
      "Predicted class for DSC08891.JPG: Class 3\n",
      "Processing file: DSC09035.JPG\n",
      "Predicted class for DSC09035.JPG: Class 1\n",
      "Processing file: DSC09082.JPG\n",
      "Predicted class for DSC09082.JPG: Class 1\n",
      "Processing file: DSC09116.JPG\n",
      "Predicted class for DSC09116.JPG: Class 1\n",
      "Processing file: DSC09150.JPG\n",
      "Predicted class for DSC09150.JPG: Class 1\n",
      "Processing file: DSC09175.JPG\n",
      "Predicted class for DSC09175.JPG: Class 1\n",
      "Processing file: DSC09541.JPG\n",
      "Predicted class for DSC09541.JPG: Class 0\n",
      "Processing file: DSC09564.JPG\n",
      "Predicted class for DSC09564.JPG: Class 0\n",
      "Processing file: DSC09624.JPG\n",
      "Predicted class for DSC09624.JPG: Class 0\n",
      "Processing file: DSC09660.JPG\n",
      "Predicted class for DSC09660.JPG: Class 0\n",
      "Processing file: DSC09678.JPG\n",
      "Predicted class for DSC09678.JPG: Class 0\n"
     ]
    }
   ],
   "source": [
    "# Move the model to the same device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vit_model.to(device)\n",
    "\n",
    "# Function to load an image and make a prediction\n",
    "def predict_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    input_tensor = preprocessing(image).unsqueeze(0)  # Add batch dimension\n",
    "    input_tensor = input_tensor.to(device)  # Move to device if using GPU\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = vit_model(input_tensor)\n",
    "        _, predicted_class = torch.max(output, 1)\n",
    "\n",
    "    return predicted_class.item()\n",
    "\n",
    "# Define the directory where the test images are stored\n",
    "test_dir = r'D:\\Kuliah\\Matkul\\Semester 7\\TA\\Dataset\\Test Set'\n",
    "\n",
    "# Function to run inference on all images in the test directory\n",
    "def run_inference_on_directory(test_dir):\n",
    "    # Iterate through each file in the test directory\n",
    "    for file_name in os.listdir(test_dir):\n",
    "        file_path = os.path.join(test_dir, file_name)\n",
    "        \n",
    "        # Check if the file is an image (optional check for file extension)\n",
    "        if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            print(f\"Processing file: {file_name}\")\n",
    "            \n",
    "            # Run the prediction on the image\n",
    "            predicted_class = predict_image(file_path)\n",
    "            print(f\"Predicted class for {file_name}: Class {predicted_class}\")\n",
    "\n",
    "# Run inference on the entire test dataset\n",
    "run_inference_on_directory(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with 100 Epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models.vision_transformer import vit_b_32\n",
    "\n",
    "# Load the saved state dictionary\n",
    "model_path = r'D:\\Kuliah\\Matkul\\Semester 7\\TA\\Kode\\ViT\\vit_model_100_epoch.pth'\n",
    "state_dict = torch.load(model_path)\n",
    "\n",
    "# Rename keys to match the current model's expected keys\n",
    "new_state_dict = {}\n",
    "for key in state_dict.keys():\n",
    "    if key == \"heads.weight\":\n",
    "        new_state_dict[\"heads.head.weight\"] = state_dict[key]\n",
    "    elif key == \"heads.bias\":\n",
    "        new_state_dict[\"heads.head.bias\"] = state_dict[key]\n",
    "    else:\n",
    "        new_state_dict[key] = state_dict[key]\n",
    "\n",
    "# Initialize the model\n",
    "vit_model = vit_b_32()\n",
    "\n",
    "# Replace the classification head to match your saved model\n",
    "vit_model.heads.head = torch.nn.Linear(vit_model.heads.head.in_features, 8)\n",
    "\n",
    "# Load the updated state dictionary\n",
    "vit_model.load_state_dict(new_state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "vit_model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: DSC06492.JPG\n",
      "Predicted class for DSC06492.JPG: Class 7\n",
      "Processing file: DSC06509.JPG\n",
      "Predicted class for DSC06509.JPG: Class 7\n",
      "Processing file: DSC06530.JPG\n",
      "Predicted class for DSC06530.JPG: Class 7\n",
      "Processing file: DSC06543.JPG\n",
      "Predicted class for DSC06543.JPG: Class 7\n",
      "Processing file: DSC06587.JPG\n",
      "Predicted class for DSC06587.JPG: Class 7\n",
      "Processing file: DSC06884.JPG\n",
      "Predicted class for DSC06884.JPG: Class 6\n",
      "Processing file: DSC06927.JPG\n",
      "Predicted class for DSC06927.JPG: Class 6\n",
      "Processing file: DSC07006.JPG\n",
      "Predicted class for DSC07006.JPG: Class 6\n",
      "Processing file: DSC07031.JPG\n",
      "Predicted class for DSC07031.JPG: Class 6\n",
      "Processing file: DSC07109.JPG\n",
      "Predicted class for DSC07109.JPG: Class 6\n",
      "Processing file: DSC07301.JPG\n",
      "Predicted class for DSC07301.JPG: Class 5\n",
      "Processing file: DSC07490.JPG\n",
      "Predicted class for DSC07490.JPG: Class 5\n",
      "Processing file: DSC07513.JPG\n",
      "Predicted class for DSC07513.JPG: Class 5\n",
      "Processing file: DSC07535.JPG\n",
      "Predicted class for DSC07535.JPG: Class 5\n",
      "Processing file: DSC07623.JPG\n",
      "Predicted class for DSC07623.JPG: Class 5\n",
      "Processing file: DSC07715.JPG\n",
      "Predicted class for DSC07715.JPG: Class 4\n",
      "Processing file: DSC07753.JPG\n",
      "Predicted class for DSC07753.JPG: Class 4\n",
      "Processing file: DSC07897.JPG\n",
      "Predicted class for DSC07897.JPG: Class 4\n",
      "Processing file: DSC07971.JPG\n",
      "Predicted class for DSC07971.JPG: Class 4\n",
      "Processing file: DSC07975.JPG\n",
      "Predicted class for DSC07975.JPG: Class 4\n",
      "Processing file: DSC08228.JPG\n",
      "Predicted class for DSC08228.JPG: Class 3\n",
      "Processing file: DSC08241.JPG\n",
      "Predicted class for DSC08241.JPG: Class 3\n",
      "Processing file: DSC08262.JPG\n",
      "Predicted class for DSC08262.JPG: Class 3\n",
      "Processing file: DSC08283.JPG\n",
      "Predicted class for DSC08283.JPG: Class 3\n",
      "Processing file: DSC08550.JPG\n",
      "Predicted class for DSC08550.JPG: Class 3\n",
      "Processing file: DSC08602.JPG\n",
      "Predicted class for DSC08602.JPG: Class 2\n",
      "Processing file: DSC08656.JPG\n",
      "Predicted class for DSC08656.JPG: Class 2\n",
      "Processing file: DSC08788.JPG\n",
      "Predicted class for DSC08788.JPG: Class 2\n",
      "Processing file: DSC08833.JPG\n",
      "Predicted class for DSC08833.JPG: Class 2\n",
      "Processing file: DSC08891.JPG\n",
      "Predicted class for DSC08891.JPG: Class 2\n",
      "Processing file: DSC09035.JPG\n",
      "Predicted class for DSC09035.JPG: Class 1\n",
      "Processing file: DSC09082.JPG\n",
      "Predicted class for DSC09082.JPG: Class 1\n",
      "Processing file: DSC09116.JPG\n",
      "Predicted class for DSC09116.JPG: Class 1\n",
      "Processing file: DSC09150.JPG\n",
      "Predicted class for DSC09150.JPG: Class 1\n",
      "Processing file: DSC09175.JPG\n",
      "Predicted class for DSC09175.JPG: Class 1\n",
      "Processing file: DSC09541.JPG\n",
      "Predicted class for DSC09541.JPG: Class 0\n",
      "Processing file: DSC09564.JPG\n",
      "Predicted class for DSC09564.JPG: Class 0\n",
      "Processing file: DSC09624.JPG\n",
      "Predicted class for DSC09624.JPG: Class 0\n",
      "Processing file: DSC09660.JPG\n",
      "Predicted class for DSC09660.JPG: Class 0\n",
      "Processing file: DSC09678.JPG\n",
      "Predicted class for DSC09678.JPG: Class 0\n"
     ]
    }
   ],
   "source": [
    "# Move the model to the same device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vit_model.to(device)\n",
    "\n",
    "# Function to load an image and make a prediction\n",
    "def predict_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    input_tensor = preprocessing(image).unsqueeze(0)  # Add batch dimension\n",
    "    input_tensor = input_tensor.to(device)  # Move to device if using GPU\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = vit_model(input_tensor)\n",
    "        _, predicted_class = torch.max(output, 1)\n",
    "\n",
    "    return predicted_class.item()\n",
    "\n",
    "# Define the directory where the test images are stored\n",
    "test_dir = r'D:\\Kuliah\\Matkul\\Semester 7\\TA\\Dataset\\Test Set'\n",
    "\n",
    "# Function to run inference on all images in the test directory\n",
    "def run_inference_on_directory(test_dir):\n",
    "    # Iterate through each file in the test directory\n",
    "    for file_name in os.listdir(test_dir):\n",
    "        file_path = os.path.join(test_dir, file_name)\n",
    "        \n",
    "        # Check if the file is an image (optional check for file extension)\n",
    "        if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            print(f\"Processing file: {file_name}\")\n",
    "            \n",
    "            # Run the prediction on the image\n",
    "            predicted_class = predict_image(file_path)\n",
    "            print(f\"Predicted class for {file_name}: Class {predicted_class}\")\n",
    "\n",
    "# Run inference on the entire test dataset\n",
    "run_inference_on_directory(test_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
